{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e911864",
   "metadata": {},
   "source": [
    "# Feature selection methods: Backward elimination, forward selection, and LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26f25d",
   "metadata": {},
   "source": [
    "Feature selection is an essential part of building efficient machine learning models. By selecting the most relevant features, you can improve model performance, reduce overfitting, and enhance interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71991b1",
   "metadata": {},
   "source": [
    "## Backward elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e127735",
   "metadata": {},
   "source": [
    "The goal is eliminate features that do not contribute much to the predictive power of a given model.\n",
    "\n",
    "Steps of backward elimination:\n",
    "1. Fit the model - e.g., linear regression - with all the features in the dataset\n",
    "2. Calculate p-values to determine how statistically siginicant each feature is\n",
    "3. Remove the least siginificant feature - i.e., the feature with the highest p-value\n",
    "4. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349a4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797be788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
    "    'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df[['StudyHours', 'PrevExamScore']]\n",
    "y = df['Pass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697d57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the model\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33859b9",
   "metadata": {},
   "source": [
    "Fit the intial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e12e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Pass   R-squared:                       0.758\n",
      "Model:                            OLS   Adj. R-squared:                  0.688\n",
      "Method:                 Least Squares   F-statistic:                     10.94\n",
      "Date:                Sat, 19 Jul 2025   Prob (F-statistic):            0.00701\n",
      "Time:                        15:41:24   Log-Likelihood:               -0.17258\n",
      "No. Observations:                  10   AIC:                             6.345\n",
      "Df Residuals:                       7   BIC:                             7.253\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.3333      1.464     -0.228      0.826      -3.796       3.129\n",
      "StudyHours        0.1515      0.324      0.468      0.654      -0.615       0.918\n",
      "PrevExamScore -2.429e-16      0.054  -4.52e-15      1.000      -0.127       0.127\n",
      "==============================================================================\n",
      "Omnibus:                        0.086   Durbin-Watson:                   1.491\n",
      "Prob(Omnibus):                  0.958   Jarque-Bera (JB):                0.311\n",
      "Skew:                           0.000   Prob(JB):                        0.856\n",
      "Kurtosis:                       2.136   Cond. No.                     1.01e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.01e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\messa\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using Ordinary Least Squares (OLS)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6451091",
   "metadata": {},
   "source": [
    "The goal is to start with all features and then progressively remove the least significant ones. The output will show a summary of the model, including the p-values for each feature. The p-value helps you determine the statistical significance of each feature: features with high p-values are considered less significant and should be removed.\n",
    "\n",
    "Steps:\n",
    "1. Fit the model with all features\n",
    "2. Identitfy the features with the highest p-value\n",
    "3. Remove the features with the highest p-value\n",
    "4. Refit the model and reapeat until all remaining features are statistically siginificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623aaf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: PrevExamScore with p-value: 0.9999999999999964\n",
      "Removing feature: const with p-value: 0.11419580126842216\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                   Pass   R-squared (uncentered):                   0.831\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.812\n",
      "Method:                 Least Squares   F-statistic:                              44.31\n",
      "Date:                Sat, 19 Jul 2025   Prob (F-statistic):                    9.31e-05\n",
      "Time:                        16:39:49   Log-Likelihood:                         -1.8294\n",
      "No. Observations:                  10   AIC:                                      5.659\n",
      "Df Residuals:                       9   BIC:                                      5.961\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "StudyHours     0.1039      0.016      6.656      0.000       0.069       0.139\n",
      "==============================================================================\n",
      "Omnibus:                        0.710   Durbin-Watson:                   1.054\n",
      "Prob(Omnibus):                  0.701   Jarque-Bera (JB):                0.557\n",
      "Skew:                          -0.000   Prob(JB):                        0.757\n",
      "Kurtosis:                       1.844   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\messa\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Define the significance level\n",
    "siginificance_level = 0.05\n",
    "\n",
    "# Perform backward elimination\n",
    "while True:\n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    # Get the highest p-value\n",
    "    max_p_value = model.pvalues.max()\n",
    "\n",
    "    # Check if the highest p-value is greater than the significance level\n",
    "    if max_p_value > siginificance_level:\n",
    "        # Identify the feature with the highest p-value\n",
    "        feature_to_remove = model.pvalues.idxmax()\n",
    "        print(f\"Removing feature: {feature_to_remove} with p-value: {max_p_value}\")\n",
    "\n",
    "        # Drop the feature\n",
    "        X = X.drop(columns=[feature_to_remove])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Display the final model summary\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
